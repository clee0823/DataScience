{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Project 2\n",
    "\n",
    "Project Description:\n",
    "- Use same datasets as Project 1.\n",
    "- Preprocess data: Explore data and apply data scaling.\n",
    "\n",
    "Regression Task:\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 2. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Classification Task:\n",
    "- Apply two voting classifiers - one with hard voting and one with soft voting\n",
    "- Apply any two models with bagging and any two models with pasting.\n",
    "- Apply any two models with adaboost boosting\n",
    "- Apply one model with gradient boosting\n",
    "- Apply PCA on data and then apply all the models in project 1 again on data you get from PCA. Compare your results with results in project 1. You don't need to apply all the models twice. Just copy the result table from project 1, prepare similar table for all the models after PCA and compare both tables. Does PCA help in getting better results?\n",
    "- Apply deep learning models covered in class\n",
    "\n",
    "Deliverables:\n",
    "- Use markdown to provide inline comments for this project.\n",
    "- Your outputs should be clearly executed in the notebook i.e. we should not need to rerun the code to obtain the outputs.\n",
    "- Visualization encouraged.\n",
    "- If you are submitting two different files, then please only one group member submit both the files. If you submit two files separately from different accounts, it will be submitted as two different attempts.\n",
    "- If you are submitting two different files, then please follow below naming convetion:\n",
    "    Project2_Regression_GroupXX_Firstname1_Firstname2.ipynb\n",
    "    Project2_Classification_GroupXX_Firstname1_Firstname2.ipynb\n",
    "- If you are submitting single file, then please follow below naming convetion:\n",
    "    Project2_Both_GroupXX_Firstname1_Firstname2.ipynb\n",
    "\n",
    "Questions regarding the project:\n",
    "- We have created a discussion board under Projects folder on e-learning. Create threads over there and post your queries related to project there.\n",
    "- We will also answer queries there. We will not be answering any project related queries through the mail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "from  sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "# softmax regression\n",
    "\n",
    "ar = pd.read_csv('audit_risk.csv')\n",
    "tr = pd.read_csv('trial.csv')\n",
    "# comapre column names \n",
    "ar_cols = ar.columns\n",
    "tr_cols = tr.columns\n",
    "\n",
    "ar.rename(columns={'Risk':'aRisk'}, inplace=True)\n",
    "common_cols = ar_cols.intersection(tr_cols)\n",
    "ar_not_tr = ar_cols.difference(tr_cols)\n",
    "tr_not_ar = tr_cols.difference(ar_cols)\n",
    "\n",
    "df = pd.concat([ar,tr[tr_not_ar]], axis=1)\n",
    "\n",
    "df['Money_Value'].mean()\n",
    "df.loc[642,'Money_Value'] = 14.14\n",
    "dfx = df\n",
    "\n",
    "# compare row values from ar and tr from columns with common names\n",
    "dfx = dfx.reset_index(drop=True)\n",
    "dfx_gpby = dfx.groupby(list(dfx.columns)) #group by\n",
    "idx = [x[0] for x in dfx_gpby.groups.values() if len(x) == 1] #get index of unique records\n",
    "diff_dfx = dfx.reindex(idx)\n",
    "\n",
    "dfx['LOCATION_ID']= dfx['LOCATION_ID'].str.replace(\"LOHARU\", \"1001\", case = False) \n",
    "dfx['LOCATION_ID']= dfx['LOCATION_ID'].str.replace(\"NUH\", \"1002\", case = False) \n",
    "dfx['LOCATION_ID']= dfx['LOCATION_ID'].str.replace(\"SAFIDON\", \"1003\", case = False)\n",
    "dfx['LOCATION_ID'] = dfx['LOCATION_ID'].apply(pd.to_numeric)\n",
    "\n",
    "y = dfx['History']\n",
    "X = dfx.drop(['History'], axis = 1)\n",
    "\n",
    "y.sum()/len(y)\n",
    "\n",
    "#Standard Scaler used in Classification due to Binary Values of Risk\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org) \n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hard | Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.9484536082474226\n",
      "RandomForestClassifier 0.979381443298969\n",
      "VotingClassifier 0.9484536082474226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:167: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(7)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "rnd_clf = RandomForestClassifier()\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('knn', knn_clf), ('rnd', rnd_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (knn_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9690721649484536\n",
      "SVC 0.9690721649484536\n",
      "VotingClassifier 0.9690721649484536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:167: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "svm_clf = SVC(C = 10, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('svc', svm_clf)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Running Decision Tree for Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9690721649484536\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Bagging Score for Decision Tree = 0.9690721649484536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.98\n",
      "Test score: 0.97\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Running Decision Tree for Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Pasting Score for Decision Tree = 0.9845360824742269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Running Random Forest for Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9896907216494846"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, random_state=0)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16, random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "np.sum(y_pred == y_pred_rf ) / len(y_pred)  # almost identical predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948453608247423\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Running Random Forest for Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 1.00\n",
      "Test score: 0.99\n"
     ]
    }
   ],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Adaboosting for Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###### Adaboosting for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_frs = AdaBoostClassifier(RandomForestClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_frs.fit(X_train, y_train)\n",
    "y_pred_frs = ada_frs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9690721649484536\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_frs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.990\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.936\n",
      "Accuracy on test set: 0.933\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.0001)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on Previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9707903780068728, 0.9725085910652921, 0.9707903780068728, 0.9725085910652921, 0.9725085910652921, 0.9725085910652921, 0.9707903780068728, 0.9707903780068728, 0.9690721649484536, 0.9690721649484536]\n",
      "[0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226, 0.9484536082474226]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neighbors = [1, 5, 10, 15, 20] #can test multiple neighbors for the best result\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for k in range(10,20):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_score_list.append(knn.score(X_train,y_train))\n",
    "    test_score_list.append(knn.score(X_test,y_test))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1207fe710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = range(10,20)\n",
    "%matplotlib inline\n",
    "plt.plot(x_axis, train_score_list, label = 'Train Score', c ='g')\n",
    "plt.plot(x_axis, test_score_list, label = 'Test Score', c ='b')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "#K = 14 is the best model due it's ability to imitate from the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9725\n",
      "Train score: 0.9485\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(14)\n",
    "knn.fit(X_train, y_train)\n",
    "print('Train score: {:.4f}'.format(knn.score(X_train, y_train)))\n",
    "print('Test score: {:.4f}'.format(knn.score(X_test, y_test)))\n",
    "\n",
    "#Strong model due to the plateauing parameter score, K = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.936426116838488, 0.936426116838488, 0.9862542955326461, 0.9982817869415808, 1.0, 1.0]\n",
      "[0.9329896907216495, 0.9329896907216495, 0.9690721649484536, 0.9845360824742269, 0.9845360824742269, 0.9845360824742269]\n",
      "[0.9089347079037801, 0.9862542955326461, 0.9896907216494846, 0.993127147766323, 1.0, 1.0]\n",
      "[0.9123711340206185, 0.9690721649484536, 0.9690721649484536, 0.9690721649484536, 0.9639175257731959, 0.9690721649484536]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clist = [0.001,0.01,0.1,1,10, 100]\n",
    "train_score_list_l1 = []\n",
    "test_score_list_l1 = []\n",
    "train_score_list_l2 = []\n",
    "test_score_list_l2 = []\n",
    "\n",
    "for c in clist:\n",
    "    log_l1 = LogisticRegression(penalty='l1', C=c )\n",
    "    log_l2 = LogisticRegression(penalty='l2', C=c )\n",
    "    log_l1.fit(X_train,y_train)\n",
    "    log_l2.fit(X_train,y_train)\n",
    "    train_score_list_l1.append(log_l1.score(X_train,y_train))\n",
    "    train_score_list_l2.append(log_l2.score(X_train,y_train))\n",
    "    test_score_list_l1.append(log_l1.score(X_test,y_test))\n",
    "    test_score_list_l2.append(log_l2.score(X_test,y_test))\n",
    "    \n",
    "print(train_score_list_l1)\n",
    "print(test_score_list_l1)\n",
    "print(train_score_list_l2)\n",
    "print(test_score_list_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEOCAYAAAB4nTvgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsDAMwzD88v/ToJxvL0blmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(clist, train_score_list_l1, label = 'train score, penalty = l1')\n",
    "plt.plot(clist, test_score_list_l1, label = 'test score, penalty = l1')\n",
    "plt.plot(clist, train_score_list_l2, label = 'train score, penalty = l2')\n",
    "plt.plot(clist, test_score_list_l2, label = 'test score, penalty = l2')\n",
    "plt.legend()\n",
    "plt.xlabel('Regularization parameter: C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xscale('log')\n",
    "\n",
    "#Graph below illustrates that 0.1 is the best hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training set: 0.048\n",
      "Accuracy on Testing set: 0.036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "#dtree.fit(X_train,y_train)\n",
    "#print(\"Accuracy on Training set: {:.3f}\".format(dtree.score(x_train_org,y_train)))\n",
    "#print(\"Accuracy on Testing set: {:.3f}\".format(dtree.score(x_test_org,y_test)))\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth = 4, random_state=0)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on Training set: {:.3f}\".format(dtree.score(x_train_org,y_train)))\n",
    "print(\"Accuracy on Testing set: {:.3f}\".format(dtree.score(x_test_org,y_test)))\n",
    "\n",
    "#The accuracy of the Decision Tree model is really low so not the best\n",
    "# model to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1212d8518>,\n",
       " <matplotlib.lines.Line2D at 0x1212d83c8>,\n",
       " <matplotlib.lines.Line2D at 0x1212d8c18>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weTJYOI4GlqIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn \n",
    "\n",
    "X_b = X_train[:20,[2,22]] #inherited risk and location_id \n",
    "y_b = y_train[:20]\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_b, y_b)\n",
    "\n",
    "mglearn.plots.plot_2d_separator(dtree, X_b, fill=True, eps=0.5, alpha=.4)\n",
    "mglearn.discrete_scatter(X_b[:,0], X_b[:,1], y_b)\n",
    "\n",
    "# Model shows what the result of the model will be and which\n",
    "# variables will lead to a 0 or 1 risk result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9329896907216495\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "linear_svm = LinearSVC().fit(X_train, y_train)\n",
    "linear_svm.fit(X,y)\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVC Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9432989690721649\n"
     ]
    }
   ],
   "source": [
    "linear_svm = LinearSVC()\n",
    "linear_svm.fit(X_train, y_train)\n",
    "y_pred_svm_linear = linear_svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_svm_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training set: 0.995\n",
      "Accuracy on Testing set: 0.943\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Training set: {:.3f}\".format(linear_svm.score(x_train_org,y_train)))\n",
    "print(\"Accuracy on Testing set: {:.3f}\".format(linear_svm.score(x_test_org,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Poly kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "svm_poly = SVC(kernel = 'poly')\n",
    "svm_poly.fit(X_test, y_test)\n",
    "y_pred_svm_kernel = svm_poly.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_svm_kernel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training set: 0.940\n",
      "Accuracy on Testing set: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Training set: {:.3f}\".format(svm_poly.score(x_train_org,y_train)))\n",
    "print(\"Accuracy on Testing set: {:.3f}\".format(svm_poly.score(x_test_org,y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PCA Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### KNN Result:\n",
    "##### Train score: 0.9622\n",
    "##### Test score: 0.9639\n",
    "    \n",
    "#### PCA KNN Result:\n",
    "##### Train score: 0.9725\n",
    "##### Test score: 0.9485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Logit Result:\n",
    "##### [0.5962199312714777, 0.8814432989690721, 0.9690721649484536, 0.9845360824742269, 0.9948453608247423, 0.9948453608247423]\n",
    "##### [0.6391752577319587, 0.8917525773195877, 0.9742268041237113, 0.9896907216494846, 0.9948453608247423, 0.9948453608247423]\n",
    "##### [0.9312714776632303, 0.9621993127147767, 0.9707903780068728, 0.979381443298969, 0.9862542955326461, 0.9948453608247423]\n",
    "##### [0.9278350515463918, 0.9690721649484536, 0.9742268041237113, 0.9896907216494846, 0.9896907216494846, 0.9948453608247423]    \n",
    "#### PCA Logit Result:\n",
    "##### [0.936426116838488, 0.936426116838488, 0.9862542955326461, 0.9982817869415808, 1.0, 1.0]\n",
    "##### [0.9329896907216495, 0.9329896907216495, 0.9690721649484536, 0.9845360824742269, 0.9845360824742269, 0.9845360824742269]\n",
    "##### [0.9089347079037801, 0.9862542955326461, 0.9896907216494846, 0.993127147766323, 1.0, 1.0]\n",
    "##### [0.9123711340206185, 0.9690721649484536, 0.9690721649484536, 0.9690721649484536, 0.9639175257731959, 0.9690721649484536]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree:\n",
    "##### Accuracy on Training set: 0.404\n",
    "##### Accuracy on Testing set: 0.361\n",
    "##### PCA Decision Tree Result:\n",
    "##### Accuracy on Training set: 0.048\n",
    "##### Accuracy on Testing set: 0.036"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM: \n",
    "##### Accuracy on Training set: 0.404\n",
    "##### Accuracy on Testing set: 0.376\n",
    "##### Accuracy Score Prediction: 0.9432989690721649\n",
    "\n",
    "\n",
    "#### PCA Linear SVM:\n",
    "##### Accuracy on Training set: 0.995\n",
    "##### Accuracy on Testing set: 0.943\n",
    "##### Accuracy Score Prediction: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Poly SVM:\n",
    "##### Accuracy on Training set: 0.404\n",
    "##### Accuracy on Testing set: 0.361\n",
    "##### Accuracy Score Prediction: 0.8814432989690721   \n",
    "    \n",
    "#### PCA Poly SVM:\n",
    "##### Accuracy on Training set: 0.940\n",
    "##### Accuracy on Testing set: 1.000\n",
    "##### Accuracy Score Prediction: 1.0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Conclusion: Overall, PCA improved the accuracy of the Linear and Polynomial Support Vector Machine, the Logistic Classificaiton, and KNN. The Decision Tree accuracy was the only model that had decrased in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurel Network - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(10)\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org) \n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=2, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 0.6702 - acc: 0.6100\n",
      "Epoch 2/150\n",
      "582/582 [==============================] - 0s 284us/step - loss: 0.6365 - acc: 0.8351\n",
      "Epoch 3/150\n",
      "582/582 [==============================] - 0s 239us/step - loss: 0.6043 - acc: 0.8127\n",
      "Epoch 4/150\n",
      "582/582 [==============================] - 0s 215us/step - loss: 0.5633 - acc: 0.8162\n",
      "Epoch 5/150\n",
      "582/582 [==============================] - 0s 204us/step - loss: 0.5083 - acc: 0.8265\n",
      "Epoch 6/150\n",
      "582/582 [==============================] - 0s 206us/step - loss: 0.4497 - acc: 0.8419\n",
      "Epoch 7/150\n",
      "582/582 [==============================] - 0s 205us/step - loss: 0.4038 - acc: 0.8436\n",
      "Epoch 8/150\n",
      "582/582 [==============================] - 0s 219us/step - loss: 0.3692 - acc: 0.8454\n",
      "Epoch 9/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.3445 - acc: 0.8557\n",
      "Epoch 10/150\n",
      "582/582 [==============================] - 0s 250us/step - loss: 0.3252 - acc: 0.8643\n",
      "Epoch 11/150\n",
      "582/582 [==============================] - 0s 248us/step - loss: 0.3111 - acc: 0.8625\n",
      "Epoch 12/150\n",
      "582/582 [==============================] - 0s 288us/step - loss: 0.2978 - acc: 0.8797\n",
      "Epoch 13/150\n",
      "582/582 [==============================] - 0s 215us/step - loss: 0.2877 - acc: 0.8797\n",
      "Epoch 14/150\n",
      "582/582 [==============================] - 0s 228us/step - loss: 0.2770 - acc: 0.8918\n",
      "Epoch 15/150\n",
      "582/582 [==============================] - 0s 221us/step - loss: 0.2694 - acc: 0.8969\n",
      "Epoch 16/150\n",
      "582/582 [==============================] - 0s 249us/step - loss: 0.2625 - acc: 0.9055\n",
      "Epoch 17/150\n",
      "582/582 [==============================] - 0s 302us/step - loss: 0.2527 - acc: 0.9072\n",
      "Epoch 18/150\n",
      "582/582 [==============================] - 0s 214us/step - loss: 0.2470 - acc: 0.9107\n",
      "Epoch 19/150\n",
      "582/582 [==============================] - 0s 294us/step - loss: 0.2405 - acc: 0.9175\n",
      "Epoch 20/150\n",
      "582/582 [==============================] - 0s 249us/step - loss: 0.2352 - acc: 0.9141\n",
      "Epoch 21/150\n",
      "582/582 [==============================] - 0s 206us/step - loss: 0.2298 - acc: 0.9210\n",
      "Epoch 22/150\n",
      "582/582 [==============================] - 0s 199us/step - loss: 0.2250 - acc: 0.9261\n",
      "Epoch 23/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.2201 - acc: 0.9278\n",
      "Epoch 24/150\n",
      "582/582 [==============================] - 0s 243us/step - loss: 0.2197 - acc: 0.9278\n",
      "Epoch 25/150\n",
      "582/582 [==============================] - 0s 247us/step - loss: 0.2132 - acc: 0.9278\n",
      "Epoch 26/150\n",
      "582/582 [==============================] - 0s 233us/step - loss: 0.2110 - acc: 0.9261\n",
      "Epoch 27/150\n",
      "582/582 [==============================] - 0s 198us/step - loss: 0.2064 - acc: 0.9347\n",
      "Epoch 28/150\n",
      "582/582 [==============================] - 0s 182us/step - loss: 0.2080 - acc: 0.9347\n",
      "Epoch 29/150\n",
      "582/582 [==============================] - 0s 199us/step - loss: 0.2001 - acc: 0.9381\n",
      "Epoch 30/150\n",
      "582/582 [==============================] - 0s 284us/step - loss: 0.1982 - acc: 0.9330\n",
      "Epoch 31/150\n",
      "582/582 [==============================] - 0s 315us/step - loss: 0.1993 - acc: 0.9330\n",
      "Epoch 32/150\n",
      "582/582 [==============================] - 0s 298us/step - loss: 0.1934 - acc: 0.9381\n",
      "Epoch 33/150\n",
      "582/582 [==============================] - 0s 222us/step - loss: 0.1926 - acc: 0.9330\n",
      "Epoch 34/150\n",
      "582/582 [==============================] - 0s 204us/step - loss: 0.1891 - acc: 0.9313\n",
      "Epoch 35/150\n",
      "582/582 [==============================] - 0s 199us/step - loss: 0.1915 - acc: 0.9364\n",
      "Epoch 36/150\n",
      "582/582 [==============================] - 0s 210us/step - loss: 0.1891 - acc: 0.9313\n",
      "Epoch 37/150\n",
      "582/582 [==============================] - 0s 244us/step - loss: 0.1839 - acc: 0.9381\n",
      "Epoch 38/150\n",
      "582/582 [==============================] - 0s 284us/step - loss: 0.1887 - acc: 0.9313\n",
      "Epoch 39/150\n",
      "582/582 [==============================] - 0s 248us/step - loss: 0.1818 - acc: 0.9330\n",
      "Epoch 40/150\n",
      "582/582 [==============================] - 0s 232us/step - loss: 0.1830 - acc: 0.9347\n",
      "Epoch 41/150\n",
      "582/582 [==============================] - 0s 271us/step - loss: 0.1831 - acc: 0.9296\n",
      "Epoch 42/150\n",
      "582/582 [==============================] - 0s 206us/step - loss: 0.1787 - acc: 0.9296\n",
      "Epoch 43/150\n",
      "582/582 [==============================] - 0s 257us/step - loss: 0.1790 - acc: 0.9330\n",
      "Epoch 44/150\n",
      "582/582 [==============================] - 0s 312us/step - loss: 0.1785 - acc: 0.9313\n",
      "Epoch 45/150\n",
      "582/582 [==============================] - 0s 263us/step - loss: 0.1750 - acc: 0.9330\n",
      "Epoch 46/150\n",
      "582/582 [==============================] - 0s 198us/step - loss: 0.1815 - acc: 0.9261\n",
      "Epoch 47/150\n",
      "582/582 [==============================] - 0s 223us/step - loss: 0.1751 - acc: 0.9278\n",
      "Epoch 48/150\n",
      "582/582 [==============================] - 0s 231us/step - loss: 0.1727 - acc: 0.9313\n",
      "Epoch 49/150\n",
      "582/582 [==============================] - 0s 235us/step - loss: 0.1738 - acc: 0.9330\n",
      "Epoch 50/150\n",
      "582/582 [==============================] - 0s 232us/step - loss: 0.1719 - acc: 0.9296\n",
      "Epoch 51/150\n",
      "582/582 [==============================] - 0s 265us/step - loss: 0.1712 - acc: 0.9330\n",
      "Epoch 52/150\n",
      "582/582 [==============================] - 0s 261us/step - loss: 0.1738 - acc: 0.9278\n",
      "Epoch 53/150\n",
      "582/582 [==============================] - 0s 223us/step - loss: 0.1742 - acc: 0.9278\n",
      "Epoch 54/150\n",
      "582/582 [==============================] - 0s 228us/step - loss: 0.1700 - acc: 0.9278\n",
      "Epoch 55/150\n",
      "582/582 [==============================] - 0s 239us/step - loss: 0.1731 - acc: 0.9313\n",
      "Epoch 56/150\n",
      "582/582 [==============================] - 0s 224us/step - loss: 0.1683 - acc: 0.9313\n",
      "Epoch 57/150\n",
      "582/582 [==============================] - 0s 204us/step - loss: 0.1675 - acc: 0.9364\n",
      "Epoch 58/150\n",
      "582/582 [==============================] - 0s 265us/step - loss: 0.1666 - acc: 0.9313\n",
      "Epoch 59/150\n",
      "582/582 [==============================] - 0s 319us/step - loss: 0.1670 - acc: 0.9296\n",
      "Epoch 60/150\n",
      "582/582 [==============================] - 0s 227us/step - loss: 0.1669 - acc: 0.9364\n",
      "Epoch 61/150\n",
      "582/582 [==============================] - 0s 245us/step - loss: 0.1661 - acc: 0.9364\n",
      "Epoch 62/150\n",
      "582/582 [==============================] - 0s 202us/step - loss: 0.1663 - acc: 0.9364\n",
      "Epoch 63/150\n",
      "582/582 [==============================] - 0s 204us/step - loss: 0.1658 - acc: 0.9330\n",
      "Epoch 64/150\n",
      "582/582 [==============================] - 0s 248us/step - loss: 0.1644 - acc: 0.9330\n",
      "Epoch 65/150\n",
      "582/582 [==============================] - 0s 292us/step - loss: 0.1639 - acc: 0.9330\n",
      "Epoch 66/150\n",
      "582/582 [==============================] - 0s 288us/step - loss: 0.1662 - acc: 0.9347\n",
      "Epoch 67/150\n",
      "582/582 [==============================] - 0s 272us/step - loss: 0.1694 - acc: 0.9278\n",
      "Epoch 68/150\n",
      "582/582 [==============================] - 0s 215us/step - loss: 0.1644 - acc: 0.9296\n",
      "Epoch 69/150\n",
      "582/582 [==============================] - 0s 219us/step - loss: 0.1649 - acc: 0.9347\n",
      "Epoch 70/150\n",
      "582/582 [==============================] - 0s 201us/step - loss: 0.1631 - acc: 0.9330\n",
      "Epoch 71/150\n",
      "582/582 [==============================] - 0s 218us/step - loss: 0.1646 - acc: 0.9313\n",
      "Epoch 72/150\n",
      "582/582 [==============================] - 0s 234us/step - loss: 0.1619 - acc: 0.9364\n",
      "Epoch 73/150\n",
      "582/582 [==============================] - 0s 258us/step - loss: 0.1634 - acc: 0.9278\n",
      "Epoch 74/150\n",
      "582/582 [==============================] - 0s 275us/step - loss: 0.1645 - acc: 0.9313\n",
      "Epoch 75/150\n",
      "582/582 [==============================] - 0s 218us/step - loss: 0.1615 - acc: 0.9364\n",
      "Epoch 76/150\n",
      "582/582 [==============================] - ETA: 0s - loss: 0.1761 - acc: 0.916 - 0s 213us/step - loss: 0.1622 - acc: 0.9227\n",
      "Epoch 77/150\n",
      "582/582 [==============================] - 0s 207us/step - loss: 0.1641 - acc: 0.9278\n",
      "Epoch 78/150\n",
      "582/582 [==============================] - ETA: 0s - loss: 0.1602 - acc: 0.933 - 0s 219us/step - loss: 0.1605 - acc: 0.9330\n",
      "Epoch 79/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.1614 - acc: 0.9330\n",
      "Epoch 80/150\n",
      "582/582 [==============================] - 0s 259us/step - loss: 0.1604 - acc: 0.9296\n",
      "Epoch 81/150\n",
      "582/582 [==============================] - 0s 217us/step - loss: 0.1609 - acc: 0.9278\n",
      "Epoch 82/150\n",
      "582/582 [==============================] - 0s 228us/step - loss: 0.1633 - acc: 0.9296\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 0s 201us/step - loss: 0.1644 - acc: 0.9313\n",
      "Epoch 84/150\n",
      "582/582 [==============================] - 0s 218us/step - loss: 0.1594 - acc: 0.9364\n",
      "Epoch 85/150\n",
      "582/582 [==============================] - 0s 200us/step - loss: 0.1671 - acc: 0.9296\n",
      "Epoch 86/150\n",
      "582/582 [==============================] - 0s 228us/step - loss: 0.1625 - acc: 0.9433\n",
      "Epoch 87/150\n",
      "582/582 [==============================] - 0s 300us/step - loss: 0.1610 - acc: 0.9313\n",
      "Epoch 88/150\n",
      "582/582 [==============================] - 0s 252us/step - loss: 0.1596 - acc: 0.9330\n",
      "Epoch 89/150\n",
      "582/582 [==============================] - 0s 237us/step - loss: 0.1585 - acc: 0.9313 0s - loss: 0.2009 - acc: 0.91\n",
      "Epoch 90/150\n",
      "582/582 [==============================] - 0s 220us/step - loss: 0.1593 - acc: 0.9313\n",
      "Epoch 91/150\n",
      "582/582 [==============================] - 0s 237us/step - loss: 0.1588 - acc: 0.9278\n",
      "Epoch 92/150\n",
      "582/582 [==============================] - 0s 206us/step - loss: 0.1587 - acc: 0.9296\n",
      "Epoch 93/150\n",
      "582/582 [==============================] - 0s 207us/step - loss: 0.1587 - acc: 0.9278\n",
      "Epoch 94/150\n",
      "582/582 [==============================] - 0s 251us/step - loss: 0.1605 - acc: 0.9347\n",
      "Epoch 95/150\n",
      "582/582 [==============================] - 0s 285us/step - loss: 0.1609 - acc: 0.9330\n",
      "Epoch 96/150\n",
      "582/582 [==============================] - 0s 231us/step - loss: 0.1578 - acc: 0.9313\n",
      "Epoch 97/150\n",
      "582/582 [==============================] - 0s 217us/step - loss: 0.1625 - acc: 0.9364\n",
      "Epoch 98/150\n",
      "582/582 [==============================] - 0s 233us/step - loss: 0.1588 - acc: 0.9330\n",
      "Epoch 99/150\n",
      "582/582 [==============================] - 0s 215us/step - loss: 0.1570 - acc: 0.9278\n",
      "Epoch 100/150\n",
      "582/582 [==============================] - 0s 234us/step - loss: 0.1580 - acc: 0.9330\n",
      "Epoch 101/150\n",
      "582/582 [==============================] - 0s 253us/step - loss: 0.1599 - acc: 0.9313\n",
      "Epoch 102/150\n",
      "582/582 [==============================] - 0s 292us/step - loss: 0.1588 - acc: 0.9296 0s - loss: 0.1607 - acc: 0.930\n",
      "Epoch 103/150\n",
      "582/582 [==============================] - 0s 228us/step - loss: 0.1570 - acc: 0.9330\n",
      "Epoch 104/150\n",
      "582/582 [==============================] - 0s 212us/step - loss: 0.1611 - acc: 0.9296\n",
      "Epoch 105/150\n",
      "582/582 [==============================] - 0s 235us/step - loss: 0.1584 - acc: 0.9313\n",
      "Epoch 106/150\n",
      "582/582 [==============================] - 0s 220us/step - loss: 0.1578 - acc: 0.9330\n",
      "Epoch 107/150\n",
      "582/582 [==============================] - 0s 264us/step - loss: 0.1587 - acc: 0.9278\n",
      "Epoch 108/150\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.1577 - acc: 0.9296\n",
      "Epoch 109/150\n",
      "582/582 [==============================] - 0s 273us/step - loss: 0.1590 - acc: 0.9330\n",
      "Epoch 110/150\n",
      "582/582 [==============================] - 0s 263us/step - loss: 0.1611 - acc: 0.9347\n",
      "Epoch 111/150\n",
      "582/582 [==============================] - 0s 269us/step - loss: 0.1590 - acc: 0.9278\n",
      "Epoch 112/150\n",
      "582/582 [==============================] - 0s 309us/step - loss: 0.1578 - acc: 0.9296\n",
      "Epoch 113/150\n",
      "582/582 [==============================] - 0s 275us/step - loss: 0.1565 - acc: 0.9330\n",
      "Epoch 114/150\n",
      "582/582 [==============================] - 0s 267us/step - loss: 0.1567 - acc: 0.9364\n",
      "Epoch 115/150\n",
      "582/582 [==============================] - 0s 312us/step - loss: 0.1579 - acc: 0.9330\n",
      "Epoch 116/150\n",
      "582/582 [==============================] - 0s 263us/step - loss: 0.1556 - acc: 0.9364\n",
      "Epoch 117/150\n",
      "582/582 [==============================] - 0s 210us/step - loss: 0.1561 - acc: 0.9313\n",
      "Epoch 118/150\n",
      "582/582 [==============================] - 0s 208us/step - loss: 0.1557 - acc: 0.9330\n",
      "Epoch 119/150\n",
      "582/582 [==============================] - 0s 268us/step - loss: 0.1568 - acc: 0.9364\n",
      "Epoch 120/150\n",
      "582/582 [==============================] - 0s 312us/step - loss: 0.1584 - acc: 0.9330\n",
      "Epoch 121/150\n",
      "582/582 [==============================] - 0s 243us/step - loss: 0.1554 - acc: 0.9278\n",
      "Epoch 122/150\n",
      "582/582 [==============================] - 0s 232us/step - loss: 0.1570 - acc: 0.9330\n",
      "Epoch 123/150\n",
      "582/582 [==============================] - 0s 212us/step - loss: 0.1562 - acc: 0.9296\n",
      "Epoch 124/150\n",
      "582/582 [==============================] - 0s 211us/step - loss: 0.1589 - acc: 0.9313\n",
      "Epoch 125/150\n",
      "582/582 [==============================] - 0s 262us/step - loss: 0.1568 - acc: 0.9296\n",
      "Epoch 126/150\n",
      "582/582 [==============================] - 0s 233us/step - loss: 0.1574 - acc: 0.9313\n",
      "Epoch 127/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.1559 - acc: 0.9330\n",
      "Epoch 128/150\n",
      "582/582 [==============================] - 0s 305us/step - loss: 0.1570 - acc: 0.9313\n",
      "Epoch 129/150\n",
      "582/582 [==============================] - 0s 213us/step - loss: 0.1546 - acc: 0.9330\n",
      "Epoch 130/150\n",
      "582/582 [==============================] - 0s 218us/step - loss: 0.1544 - acc: 0.9296\n",
      "Epoch 131/150\n",
      "582/582 [==============================] - 0s 207us/step - loss: 0.1594 - acc: 0.9313\n",
      "Epoch 132/150\n",
      "582/582 [==============================] - 0s 220us/step - loss: 0.1581 - acc: 0.9347\n",
      "Epoch 133/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.1548 - acc: 0.9330\n",
      "Epoch 134/150\n",
      "582/582 [==============================] - 0s 301us/step - loss: 0.1542 - acc: 0.9330\n",
      "Epoch 135/150\n",
      "582/582 [==============================] - 0s 281us/step - loss: 0.1546 - acc: 0.9347\n",
      "Epoch 136/150\n",
      "582/582 [==============================] - 0s 221us/step - loss: 0.1554 - acc: 0.9330\n",
      "Epoch 137/150\n",
      "582/582 [==============================] - 0s 217us/step - loss: 0.1560 - acc: 0.9347\n",
      "Epoch 138/150\n",
      "582/582 [==============================] - 0s 250us/step - loss: 0.1531 - acc: 0.9347\n",
      "Epoch 139/150\n",
      "582/582 [==============================] - 0s 235us/step - loss: 0.1544 - acc: 0.9313\n",
      "Epoch 140/150\n",
      "582/582 [==============================] - 0s 245us/step - loss: 0.1535 - acc: 0.9330\n",
      "Epoch 141/150\n",
      "582/582 [==============================] - 0s 336us/step - loss: 0.1572 - acc: 0.9313\n",
      "Epoch 142/150\n",
      "582/582 [==============================] - 0s 256us/step - loss: 0.1558 - acc: 0.9330 0s - loss: 0.2102 - acc: 0.91\n",
      "Epoch 143/150\n",
      "582/582 [==============================] - 0s 231us/step - loss: 0.1544 - acc: 0.9330\n",
      "Epoch 144/150\n",
      "582/582 [==============================] - 0s 214us/step - loss: 0.1536 - acc: 0.9296\n",
      "Epoch 145/150\n",
      "582/582 [==============================] - 0s 235us/step - loss: 0.1536 - acc: 0.9347\n",
      "Epoch 146/150\n",
      "582/582 [==============================] - 0s 235us/step - loss: 0.1532 - acc: 0.9313\n",
      "Epoch 147/150\n",
      "582/582 [==============================] - 0s 211us/step - loss: 0.1553 - acc: 0.9330\n",
      "Epoch 148/150\n",
      "582/582 [==============================] - 0s 314us/step - loss: 0.1562 - acc: 0.9313\n",
      "Epoch 149/150\n",
      "582/582 [==============================] - 0s 273us/step - loss: 0.1545 - acc: 0.9296\n",
      "Epoch 150/150\n",
      "582/582 [==============================] - 0s 213us/step - loss: 0.1565 - acc: 0.9347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127e5e780>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 847us/step\n",
      "\n",
      "acc: 93.30%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [0.0056498 ],\n",
       "       [0.00793771],\n",
       "       [0.99999416],\n",
       "       [0.01857417],\n",
       "       [0.01399356],\n",
       "       [0.07592128],\n",
       "       [0.00845857],\n",
       "       [0.07696842],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.00600959],\n",
       "       [0.04905406],\n",
       "       [1.        ],\n",
       "       [0.03300349],\n",
       "       [0.03260681],\n",
       "       [0.9970415 ],\n",
       "       [0.9999764 ],\n",
       "       [0.22660244],\n",
       "       [0.02480831],\n",
       "       [0.18802428],\n",
       "       [0.00600567],\n",
       "       [0.00783223],\n",
       "       [1.        ],\n",
       "       [0.03560997],\n",
       "       [1.        ],\n",
       "       [0.01732446],\n",
       "       [0.6364301 ],\n",
       "       [0.09566218],\n",
       "       [0.0056735 ],\n",
       "       [0.03431503],\n",
       "       [0.06661424],\n",
       "       [1.        ],\n",
       "       [0.2933437 ],\n",
       "       [0.00797415],\n",
       "       [0.03627653],\n",
       "       [0.01662322],\n",
       "       [0.08420402],\n",
       "       [1.        ],\n",
       "       [0.07267378],\n",
       "       [1.        ],\n",
       "       [0.9243253 ],\n",
       "       [0.98251396],\n",
       "       [1.        ],\n",
       "       [0.01083868],\n",
       "       [0.0264571 ],\n",
       "       [0.9950511 ],\n",
       "       [0.04132147],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.07228577],\n",
       "       [0.00747593],\n",
       "       [0.3181772 ],\n",
       "       [0.00713223],\n",
       "       [0.99999905],\n",
       "       [0.03110017],\n",
       "       [0.06377373],\n",
       "       [0.20059161],\n",
       "       [0.37167296],\n",
       "       [0.04269851],\n",
       "       [0.08034084],\n",
       "       [1.        ],\n",
       "       [0.9269939 ],\n",
       "       [0.00863391],\n",
       "       [0.01907905],\n",
       "       [1.        ],\n",
       "       [0.0128187 ],\n",
       "       [0.02480323],\n",
       "       [0.51712084],\n",
       "       [0.00577912],\n",
       "       [0.4346933 ],\n",
       "       [0.9999535 ],\n",
       "       [1.        ],\n",
       "       [0.01887382],\n",
       "       [0.02963916],\n",
       "       [0.00697862],\n",
       "       [0.00642964],\n",
       "       [0.01309859],\n",
       "       [1.        ],\n",
       "       [0.00596964],\n",
       "       [0.00633036],\n",
       "       [0.99847573],\n",
       "       [0.0242537 ],\n",
       "       [1.        ],\n",
       "       [0.01619686],\n",
       "       [1.        ],\n",
       "       [0.18932296],\n",
       "       [0.00646449],\n",
       "       [0.06962784],\n",
       "       [0.04636486],\n",
       "       [1.        ],\n",
       "       [0.00735858],\n",
       "       [0.02798918],\n",
       "       [0.23473126],\n",
       "       [0.9996039 ],\n",
       "       [0.00869368],\n",
       "       [0.01028951],\n",
       "       [0.01517751],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.08894885],\n",
       "       [0.06950337],\n",
       "       [0.99999475],\n",
       "       [0.06882212],\n",
       "       [0.00678171],\n",
       "       [0.00629108],\n",
       "       [0.03446215],\n",
       "       [0.07109322],\n",
       "       [0.8204373 ],\n",
       "       [0.00743074],\n",
       "       [0.01268524],\n",
       "       [0.00695695],\n",
       "       [0.14964288],\n",
       "       [1.        ],\n",
       "       [0.935044  ],\n",
       "       [0.0486126 ],\n",
       "       [0.9907205 ],\n",
       "       [0.9915638 ],\n",
       "       [0.00694974],\n",
       "       [0.15402535],\n",
       "       [0.48899594],\n",
       "       [0.01025738],\n",
       "       [1.        ],\n",
       "       [0.02537366],\n",
       "       [1.        ],\n",
       "       [0.689584  ],\n",
       "       [0.00752474],\n",
       "       [0.961203  ],\n",
       "       [0.0597425 ],\n",
       "       [0.12437848],\n",
       "       [0.00775323],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.06430998],\n",
       "       [0.01138528],\n",
       "       [0.03906882],\n",
       "       [0.07354989],\n",
       "       [0.9999969 ],\n",
       "       [1.        ],\n",
       "       [0.01975527],\n",
       "       [0.6618232 ],\n",
       "       [0.0187783 ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.9999914 ],\n",
       "       [0.03211309],\n",
       "       [0.73917854],\n",
       "       [0.02165344],\n",
       "       [0.0111195 ],\n",
       "       [0.14451584],\n",
       "       [0.04888008],\n",
       "       [1.        ],\n",
       "       [0.00622379],\n",
       "       [0.00758983],\n",
       "       [1.        ],\n",
       "       [0.98080564],\n",
       "       [0.00740777],\n",
       "       [1.        ],\n",
       "       [0.8748815 ],\n",
       "       [0.01408934],\n",
       "       [0.9165085 ],\n",
       "       [0.09171082],\n",
       "       [0.05795578],\n",
       "       [0.66087854],\n",
       "       [0.07669792],\n",
       "       [0.01929734],\n",
       "       [0.5746359 ],\n",
       "       [0.01020956],\n",
       "       [0.3417903 ],\n",
       "       [0.9949911 ],\n",
       "       [0.0382362 ],\n",
       "       [0.00696416],\n",
       "       [0.3321411 ],\n",
       "       [0.43002942],\n",
       "       [0.9999931 ],\n",
       "       [1.        ],\n",
       "       [0.0059558 ],\n",
       "       [0.07267378],\n",
       "       [0.01240578],\n",
       "       [0.10645877],\n",
       "       [0.03627653],\n",
       "       [0.00775323],\n",
       "       [1.        ],\n",
       "       [0.01192757],\n",
       "       [1.        ],\n",
       "       [0.16088504],\n",
       "       [0.00587579],\n",
       "       [0.00571626],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.04841413]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
